{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f5dd47-de6c-4d5b-90d7-7273252d4afd",
   "metadata": {},
   "source": [
    "# Citi Bike Manhattan Filtering\n",
    "\n",
    "---\n",
    "Last Edited : 2023/12/10 by Leonard Tsai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ffbdd",
   "metadata": {},
   "source": [
    "# 1. Filter Manhanttan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fcc84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Define your functions for processing each file\n",
    "def process_csv(csv_file):\n",
    "    selected_columns = ['started_at', 'start_lat', 'start_lng']\n",
    "    # Manhattan polygon boundaries \n",
    "    manhattan = gpd.read_file(\"manhattan-island.geojson\")\n",
    "\n",
    "    _df = pd.read_csv(csv_file)\n",
    "    df = _df[selected_columns]\n",
    "    del _df\n",
    "\n",
    "    # Convert 'started_at' to datetime\n",
    "    df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "    # Add 9 minutes to each entry\n",
    "    df['started_at'] = df['started_at'] + pd.to_timedelta('9 minutes')\n",
    "    # Convert 'started_at' to the desired format\n",
    "    df['started_at'] = df['started_at'].dt.strftime('%Y%m%d %H')\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['start_lng'], df['start_lat']))\n",
    "    gdf.crs = 'EPSG:4326'\n",
    "    gdf = gdf[['started_at', 'geometry']]\n",
    "    del df\n",
    "\n",
    "    gdf_filtered = gpd.sjoin(gdf, manhattan, how='inner', op='within').reset_index(drop=True)\n",
    "    gdf_filtered = gdf_filtered[['started_at', 'geometry']]\n",
    "\n",
    "    # Get the filename without the extension\n",
    "    file_name = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "    result_df = gdf_filtered.groupby('started_at').size().reset_index(name='count')\n",
    "    result_df.to_csv(f\"./202211-202310/{file_name}_filtered.csv\")\n",
    "    print(f\"Saved {file_name} successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551a276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/_l426jsn7b5gddd0ylpgz4nh0000gn/T/ipykernel_18213/2546030723.py:12: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  _df = pd.read_csv(csv_file)\n",
      "/Users/leonardtsai/miniconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 202311-citibike-tripdata successfully!\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"../original_data/202311-citibike-tripdata.csv\"\n",
    "process_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60619763",
   "metadata": {},
   "source": [
    "# 2. Concatenate all data and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d62c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(\"./202211-202310/new_weather_20231210.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c444bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './202211-202310'\n",
    "file_pattern = '*.csv'\n",
    "\n",
    "# Use glob to find files matching the pattern\n",
    "filtered_csv_files = sorted(glob.glob(os.path.join(folder_path, file_pattern)))\n",
    "filtered_csv_files.remove('./202211-202310/new_weather_20231210.csv')\n",
    "\n",
    "filtered_df = pd.concat([pd.read_csv(filtered_csv) for filtered_csv in filtered_csv_files], ignore_index=True).groupby('started_at')['count'].sum().reset_index().iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e98c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames based on the common columns\n",
    "merged_df = pd.merge(weather_df, filtered_df, left_on='Date', right_on='started_at', how='inner')\n",
    "\n",
    "# Drop the duplicate column (you can customize this based on your needs)\n",
    "merged_df = merged_df.drop('started_at', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4b537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"merged_weather.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
