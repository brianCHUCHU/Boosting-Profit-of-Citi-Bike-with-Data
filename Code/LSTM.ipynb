{"cells":[{"cell_type":"markdown","metadata":{},"source":["Training Phase (2021/11~2023/10)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-18T14:26:24.635239Z","iopub.status.busy":"2023-12-18T14:26:24.634354Z","iopub.status.idle":"2023-12-18T14:27:43.724861Z","shell.execute_reply":"2023-12-18T14:27:43.723275Z","shell.execute_reply.started":"2023-12-18T14:26:24.635204Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.losses import mse\n","\n","def create_sequences(data_X, data_Y, time_steps=1):\n","    x, y = [], []\n","    for i in range(len(data_X) - time_steps):\n","        x.append(data_X.iloc[i:(i + time_steps)].values)\n","        y.append(data_Y.iloc[i + time_steps-1]['count'])\n","    return np.array(x), np.array(y)\n","\n","# Check the shape of X, it should be (samples, time steps, features)\n","# Assuming X_train and X_test are your input datasets with dummy variables\n","df = pd.read_csv(\"final_merged_weather_holidays.csv\", index_col='Date')\n","train = df.iloc[:-720].copy(deep=True)\n","test = df.iloc[len(df) - 1440:].copy(deep=True)\n","\n","scaler = MinMaxScaler((-1, 1))\n","x_col = ['Temp', 'Wind', 'Humidity(%)', 'Barometer', 'Visibility',\n","       'Weather_Heavy snow', 'Weather_Sunny', 'Weather_Light snow',\n","       'Weather_Overcast', 'Weather_Dense fog', 'Weather_More clouds than sun',\n","       'Weather_Heavy rain', 'Weather_Haze', 'Weather_Light freezing rain',\n","       'Weather_Cloudy', 'Weather_Snow', 'Weather_Refreshingly cool',\n","       'Weather_Mild', 'Weather_Broken clouds', 'Weather_Passing clouds',\n","       'Weather_Fog', 'Weather_Partly cloudy', 'Weather_Partly sunny',\n","       'Weather_Clear', 'Weather_Ice fog', 'Weather_Light rain',\n","       'Weather_Cool', 'Weather_Quite cool', 'Weather_Warm', 'Weather_Rain',\n","       'Weather_Mostly cloudy', 'Weather_Cold', 'Weather_Low clouds',\n","       'Weather_Freezing rain', 'Weather_Scattered clouds',\n","       'isHoliday']\n","X_train = pd.DataFrame(scaler.fit_transform(train.drop('count', axis=1)), columns=x_col)\n","y_train = pd.DataFrame(scaler.fit_transform(train[['count']]), columns=['count'])\n","X_test = pd.DataFrame(scaler.fit_transform(test.drop('count', axis=1)), columns=x_col)\n","y_test = pd.DataFrame(scaler.fit_transform(test[['count']]), columns=['count'])\n","time_steps = 720  # You can adjust this based on the length of sequences you want\n","X_train, y_train = create_sequences(X_train, y_train, time_steps)\n","X_test, y_test = create_sequences(X_test, y_test, time_steps)\n","# Make sure to replace these with your actual data\n","\n","# Define the LSTM model\n","model = Sequential()\n","model.add(LSTM(units=50, input_shape=(time_steps, len(x_col))))\n","model.add(Dense(units=1))  # Output layer, adjust units based on your task\n","\n","\n","class PredictionCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, val_data=(X_test, y_test)):\n","        self.validation_data = val_data\n","    def on_epoch_end(self, epoch, logs={}):\n","        y_pred = self.model.predict(self.validation_data[0])\n","        global epoch_performance, loss, bat\n","        mse = tf.keras.losses.MeanSquaredError()\n","        self.model.save_weights(\"{}-{}-{}.h5\".format(loss, bat, epoch)) # save the model\n","        epoch_performance.append(mse(self.validation_data[1].T[0].reshape(-1), y_pred.reshape(-1)).numpy())\n","# batch_size = [10, 25, 50, 100, 200, 300] # 分次跑避免RAM不足\n","batch_size = [300, 500, 600] # 分次跑避免RAM不足\n","epochs = 25\n","\n","loss_func = ['mean_squared_error',\"mean_absolute_error\",\"mean_absolute_percentage_error\"]\n","loss_performance = []\n","\n","for i, loss in enumerate(loss_func):\n","    batch_performance = []\n","    model.compile(optimizer='adam', loss=loss)  # Choose an appropriate loss function\n","    for j, bat in enumerate(batch_size):\n","        epoch_performance = []\n","        # Train the model\n","        model.fit(X_train, y_train, epochs=epochs, batch_size=bat, validation_data=(X_test, y_test), callbacks=[PredictionCallback()])\n","        \n","        batch_performance.append(epoch_performance)\n","    loss_performance.append(batch_performance)"]},{"cell_type":"markdown","metadata":{},"source":["Tuning, Evaluation Phase"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-17T17:08:59.906609Z","iopub.status.busy":"2023-12-17T17:08:59.906248Z","iopub.status.idle":"2023-12-17T17:09:02.001238Z","shell.execute_reply":"2023-12-17T17:09:02.000282Z","shell.execute_reply.started":"2023-12-17T17:08:59.906584Z"},"trusted":true},"outputs":[],"source":["loss_func = ['mean_squared_error',\"mean_absolute_error\",\"mean_absolute_percentage_error\"]\n","import numpy\n","import matplotlib.pyplot as plt\n","from matplotlib import cm\n","from mpl_toolkits.mplot3d import Axes3D\n","fig, ax = plt.subplots(1,len(loss_performance), figsize = (10*len(loss_performance), 10), subplot_kw=dict(projection='3d'))\n","epochs = numpy.arange(1, 26)\n","batch_size = [10, 25, 50, 100, 200, 300,400, 500, 600]\n","for i in range(3):\n","  xx, yy = numpy.meshgrid(epochs, batch_size)\n","  print(xx.shape, yy.shape)\n","  z = numpy.array(loss_performance[i])\n","  ax[i].plot_surface(xx, yy, z,cmap=cm.coolwarm,\n","                       linewidth=0, antialiased=False) # 繪製三維曲面圖\n","  ax[i].set_title(loss_func[i], fontsize = 30)\n","  min_num = []\n","  min_value = []\n","  for j, val in enumerate(loss_performance[i]):\n","    min_value.append(min(val))\n","    min_num.append(val.index(min_value[j]))\n","  first_index = min_value.index(min(min_value))\n","  second_index = min_num[first_index]\n","  print(batch_size[first_index], second_index)\n","  print(loss_performance[i][first_index][second_index])\n","plt.savefig(\"Model_Evaluation.png\", transparent=True, bbox_inches=\"tight\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["Testing Phase (2023 Nov)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","from keras.models import load_model\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.losses import mse\n","\n","def create_sequences(data_X, data_Y, time_steps=1):\n","    x, y = [], []\n","    for i in range(len(data_X) - time_steps):\n","        x.append(data_X.iloc[i:(i + time_steps)].values)\n","        y.append(data_Y.iloc[i + time_steps]['count'])\n","    return np.array(x), np.array(y)\n","time_steps = 720\n","# Check the shape of X, it should be (samples, time steps, features)\n","# Assuming X_train and X_test are your input datasets with dummy variables\n","df = pd.read_csv('final_merged_weather_holidays.csv')\n","# df = pd.read_csv('merged_weather.csv').drop('isHoliday', axis=1)\n","train = df.iloc[:-720].copy(deep=True)\n","test = df.iloc[len(df) - time_steps - 720:].copy(deep=True)\n","\n","# print(df_nov)\n","scaler = MinMaxScaler((-1, 1))\n","scaler_pred = MinMaxScaler((-1, 1))\n","# print(df.columns)\n","x_col = ['Temp', 'Wind', 'Humidity(%)', 'Barometer', 'Visibility',\n","       'Weather_Heavy snow', 'Weather_Sunny', 'Weather_Light snow',\n","       'Weather_Overcast', 'Weather_Dense fog', 'Weather_More clouds than sun',\n","       'Weather_Heavy rain', 'Weather_Haze', 'Weather_Light freezing rain',\n","       'Weather_Cloudy', 'Weather_Snow', 'Weather_Refreshingly cool',\n","       'Weather_Mild', 'Weather_Broken clouds', 'Weather_Passing clouds',\n","       'Weather_Fog', 'Weather_Partly cloudy', 'Weather_Partly sunny',\n","       'Weather_Clear', 'Weather_Ice fog', 'Weather_Light rain',\n","       'Weather_Cool', 'Weather_Quite cool', 'Weather_Warm', 'Weather_Rain',\n","       'Weather_Mostly cloudy', 'Weather_Cold', 'Weather_Low clouds',\n","       'Weather_Freezing rain', 'Weather_Scattered clouds',\n","       'isHoliday']\n","# , 'isHoliday'\n","X_train = pd.DataFrame(scaler.fit_transform(train.drop(['count', 'Date'], axis=1)), columns=x_col)\n","y_train = pd.DataFrame(scaler.fit_transform(train[['count']]), columns=['count'])\n","X_test = pd.DataFrame(scaler_pred.fit_transform(test.drop(['count', 'Date'], axis=1)), columns=x_col)\n","y_test = pd.DataFrame(scaler_pred.fit_transform(test[['count']]), columns=['count'])\n","  # You can adjust this based on the length of sequences you want\n","X_train, y_train = create_sequences(X_train, y_train, time_steps)\n","X_test, y_test = create_sequences(X_test, y_test, time_steps)\n","\n","model = Sequential()\n","model.add(LSTM(units=50, input_shape=(time_steps, len(x_col))))\n","model.add(Dense(units=1))  # Output layer, adjust units based on your task\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mean_squared_error')  # Choose an appropriate loss function\n","# model.load_weights('mean_squared_error-10-14.h5')\n","# model.load_weights('mean_squared_error-25-49.h5')\n","model.load_weights('./pre-trained  LSTM model/mean_absolute_error-300-11.h5')\n","predictions = np.array(model.predict(X_test)).reshape(-1, 1)\n","print(mse(y_test.reshape(-1), predictions.reshape(-1)).numpy())\n","predictions = scaler_pred.inverse_transform(predictions)\n","y_test = scaler_pred.inverse_transform(y_test.reshape(-1, 1))\n","\n","# Plot the actual vs predicted values\n","plt.figure(figsize=(10, 6))\n","plt.plot(y_test, label='Actual', color='gray')\n","plt.plot(predictions, label='Predicted', color='#34b7cc')\n","plt.legend()\n","plt.title('2023 Nov Actual vs Predicted Values')\n","plt.xlabel('Time')\n","plt.ylabel('Count')\n","test = test.reset_index()\n","xticks_indices = range(time_steps, len(test), 24)\n","xticks_labels = test['Date'][xticks_indices]\n","xticks_indices = range(0, 720, 24)\n","print(len(xticks_indices), len(xticks_labels))\n","plt.xticks(xticks_indices, xticks_labels, rotation=45, fontsize=7, ha = 'right')\n","# plt.savefig(\"2023 Nov Predict.png\", transparent=True, bbox_inches=\"tight\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Prediction Example (2023/12)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_sequences(data_X, time_steps=1):\n","    x= []\n","    for i in range(len(data_X) - time_steps):\n","        x.append(data_X.iloc[i:(i + time_steps)].values)\n","    return np.array(x)\n","\n","df = pd.read_csv('202312.csv')\n","print(df.columns)\n","scaler = MinMaxScaler((-1, 1))\n","X_test = pd.DataFrame(scaler.fit_transform(df.drop('Date', axis = 1)), columns=x_col)\n","X_test = create_sequences(X_test, time_steps)\n","predictions = np.array(model.predict(X_test))\n","predictions = scaler_pred.inverse_transform(predictions)\n","predictions = predictions.reshape(-1)\n","low = []\n","high = []\n","isLow = False\n","isHigh = False\n","for i, count in enumerate(predictions):\n","    if(i == (len(predictions) - 1)):\n","        if(isLow): low[len(low) - 1].append(i)\n","        elif(isHigh): high[len(high) - 1].append(i)\n","    if(isLow):\n","        if(count < 1000): continue\n","        else:\n","            low[len(low) - 1].append(i - 1)\n","            isLow = False\n","    elif(isHigh):\n","        if(count > 4000): continue\n","        else:\n","            high[len(high) - 1].append(i - 1)\n","            isHigh = False\n","    else:\n","        if(count > 4000):\n","            isHigh = True\n","            high.append([i])\n","        elif(count < 1000):\n","            isLow = True\n","            low.append([i])\n","\n","# Plot the actual vs predicted values\n","# \n","plt.figure(figsize=(10, 6))\n","plt.plot(predictions.reshape(-1), label='Predicted Volumn', color='#34b7cc')\n","for i in low:\n","    plt.axvspan(i[0], i[1], color='#34b7cc', alpha=0.2)\n","for i in high:\n","    plt.axvspan(i[0], i[1], color='#ffcf00', alpha=0.3)\n","plt.title('2023 Dec Predicted Volume')\n","plt.xlabel('Time Steps')\n","plt.ylabel('Count')\n","plt.grid(axis = 'y')\n","plt.legend()\n","print(df.index)\n","xticks_indices = range(time_steps, len(df), 8)\n","xticks_labels = df['Date'][xticks_indices]\n","xticks_indices = range(0, len(df) - time_steps, 8)\n","plt.xticks(xticks_indices, xticks_labels, rotation=45, fontsize=7, ha = 'right')\n","\n","plt.savefig(\"2023 Dec Predict.png\", transparent=True, bbox_inches=\"tight\")\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4173680,"sourceId":7221787,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
